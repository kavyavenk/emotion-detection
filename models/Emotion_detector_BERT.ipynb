{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "BERT\n"
      ],
      "metadata": {
        "id": "VTO0nAYFVgFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets scikit-learn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    BertTokenizerFast,\n",
        "    BertForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "JAojjfsuVhhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "MODEL_NAME   = \"bert-base-uncased\"\n",
        "BATCH_SIZE   = 16\n",
        "EPOCHS       = 5\n",
        "LR           = 3e-5\n",
        "WARMUP_RATIO = 0.1\n",
        "THRESHOLD    = 0.4\n",
        "LOG_STEP     = 100\n"
      ],
      "metadata": {
        "id": "_jJ9-H-JaLnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"go_emotions\", \"simplified\")  # 28 emotions\n",
        "label_names = ds[\"train\"].features[\"labels\"].feature.names\n",
        "\n",
        "NUM_LABELS = 28\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "def tokenize_and_encode(examples):\n",
        "    encodings = tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "    # shape = (batch_in_map, 28)\n",
        "    multi_hot = np.zeros((len(examples[\"labels\"]), NUM_LABELS), dtype=np.int8)\n",
        "    for i, label_list in enumerate(examples[\"labels\"]):\n",
        "        multi_hot[i, label_list] = 1\n",
        "\n",
        "    encodings[\"labels\"] = multi_hot.tolist()\n",
        "    return encodings\n",
        "\n",
        "ds = ds.map(tokenize_and_encode, batched=True, remove_columns=[\"text\", \"id\"])\n",
        "collator = DataCollatorWithPadding(tokenizer, return_tensors=\"pt\")\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(ds[\"train\"], batch_size=BATCH_SIZE,\n",
        "                          shuffle=True, collate_fn=collator)\n",
        "val_loader = DataLoader(ds[\"validation\"], batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, collate_fn=collator)\n",
        "print(ds[\"train\"].column_names)\n",
        "print(len(ds[\"validation\"]))\n"
      ],
      "metadata": {
        "id": "3jVqwyHHiSu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    problem_type=\"multi_label_classification\",\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "K6yIFreEklFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "total_steps   = len(train_loader) * EPOCHS\n",
        "warmup_steps  = int(total_steps * WARMUP_RATIO)\n",
        "scheduler     = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "-dE7zMy-flid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "#Evaluate\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    all_logits, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            labels = batch[\"labels\"].clone().detach().to(device).float()\n",
        "\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
        "            logits = model(**inputs).logits.cpu()\n",
        "\n",
        "            all_logits.append(logits)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    logits = torch.cat(all_logits)\n",
        "    labels = torch.cat(all_labels)\n",
        "\n",
        "    preds  = (torch.sigmoid(logits) > THRESHOLD).int().numpy()\n",
        "    labels = labels.int().cpu().numpy()\n",
        "\n",
        "    # accuracy, precision, recall\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds, average=\"micro\", zero_division=0)\n",
        "    recall  = recall_score(labels, preds, average=\"micro\", zero_division=0)\n",
        "\n",
        "    #f1\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "    # stats\n",
        "    print(\"average 1's in data\", labels.sum(axis=1).mean())\n",
        "    print(\"average 1's in prediction:\", preds.sum(axis=1).mean())\n",
        "\n",
        "    return acc, precision, recall, f1\n"
      ],
      "metadata": {
        "id": "83ZrHNKQh5YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "global_step = 0\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    prog_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False)\n",
        "    for step, batch in enumerate(prog_bar, 1):\n",
        "        batch_size = len(batch[\"labels\"])\n",
        "        labels = batch[\"labels\"].clone().detach().to(device).float()\n",
        "\n",
        "        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
        "\n",
        "        # zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        outputs = model(**inputs)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        global_step += 1\n",
        "\n",
        "        if global_step % LOG_STEP == 0:\n",
        "            prog_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    acc, prec, recall, f1 = evaluate(model, val_loader)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch} |\"\n",
        "        f\"loss {avg_loss:.4f} | \"\n",
        "        f\"accuracy {acc:.4f} | \"\n",
        "        f\"Precision {prec:.4f} | \"\n",
        "        f\"Recall {recall:.4f} | \"\n",
        "        f\"F1 {f1:.4f}\")"
      ],
      "metadata": {
        "id": "oYq7gMezg5ZM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}